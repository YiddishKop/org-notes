


&lt;p&gt;
&lt;a href="http://matlab.cheme.cmu.edu/2011/10/09/graphical-methods-to-help-get-initial-guesses-for-multivariate-nonlinear-regression/" &gt;Matlab post&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;
Fit the model f(x1,x2; a,b) = a*x1 + x2^b to the data given below. This model has two independent variables, and two parameters.
&lt;/p&gt;

&lt;p&gt;
We want to do a nonlinear fit to find a and b that minimize the summed squared errors between the model predictions and the data. With only two variables, we can graph how the summed squared error varies with the parameters, which may help us get initial guesses. Let us assume the parameters lie in a range, here we choose 0 to 5. In other problems you would adjust this as needed.
&lt;/p&gt;

&lt;div class="org-src-container"&gt;

&lt;pre class="src src-python"&gt;&lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; numpy &lt;span style="color: #8b0000;"&gt;as&lt;/span&gt; np
&lt;span style="color: #8b0000;"&gt;from&lt;/span&gt; mpl_toolkits.mplot3d &lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; Axes3D
&lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style="color: #8b0000;"&gt;as&lt;/span&gt; plt

x1 = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]
x2 = [0.2, 0.4, 0.8, 0.9, 1.1, 2.1]
X = np.column_stack([x1, x2]) &lt;span style="color: #ff0000; font-weight: bold;"&gt;# independent variables&lt;/span&gt;

f = [ 3.3079,    6.6358,   10.3143,   13.6492,   17.2755,   23.6271]

fig = plt.figure()
ax = fig.gca(projection = &lt;span style="color: #228b22;"&gt;'3d'&lt;/span&gt;)

ax.plot(x1, x2, f)
ax.set_xlabel(&lt;span style="color: #228b22;"&gt;'x1'&lt;/span&gt;)
ax.set_ylabel(&lt;span style="color: #228b22;"&gt;'x2'&lt;/span&gt;)
ax.set_zlabel(&lt;span style="color: #228b22;"&gt;'f(x1,x2)'&lt;/span&gt;)

plt.savefig(&lt;span style="color: #228b22;"&gt;'images/graphical-mulvar-1.png'&lt;/span&gt;)


arange = np.linspace(0,5);
brange = np.linspace(0,5);

A,B = np.meshgrid(arange, brange)

&lt;span style="color: #8b0000;"&gt;def&lt;/span&gt; &lt;span style="color: #8b2323;"&gt;model&lt;/span&gt;(X, a, b):
    &lt;span style="color: #228b22;"&gt;'Nested function for the model'&lt;/span&gt;
    x1 = X[:, 0]
    x2 = X[:, 1]
    
    f = a * x1 + x2**b
    &lt;span style="color: #8b0000;"&gt;return&lt;/span&gt; f

&lt;span style="color: #8b0000;"&gt;@np&lt;/span&gt;.vectorize
&lt;span style="color: #8b0000;"&gt;def&lt;/span&gt; &lt;span style="color: #8b2323;"&gt;errfunc&lt;/span&gt;(a, b):
    &lt;span style="color: #ff0000; font-weight: bold;"&gt;# function for the summed squared error&lt;/span&gt;
    fit = model(X, a, b)
    sse = np.sum((fit - f)**2)
    &lt;span style="color: #8b0000;"&gt;return&lt;/span&gt; sse

SSE = errfunc(A, B)

plt.clf()
plt.contourf(A, B, SSE, 50)
plt.plot([3.2], [2.1], &lt;span style="color: #228b22;"&gt;'ro'&lt;/span&gt;)
plt.figtext( 3.4, 2.2, &lt;span style="color: #228b22;"&gt;'Minimum near here'&lt;/span&gt;, color=&lt;span style="color: #228b22;"&gt;'r'&lt;/span&gt;)

plt.savefig(&lt;span style="color: #228b22;"&gt;'images/graphical-mulvar-2.png'&lt;/span&gt;)

guesses = [3.18, 2.02]

&lt;span style="color: #8b0000;"&gt;from&lt;/span&gt; scipy.optimize &lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; curve_fit

popt, pcov = curve_fit(model, X, f, guesses)
&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt; popt

plt.plot([popt[0]], [popt[1]], &lt;span style="color: #228b22;"&gt;'r*'&lt;/span&gt;)
plt.savefig(&lt;span style="color: #228b22;"&gt;'images/graphical-mulvar-3.png'&lt;/span&gt;)

&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt; model(X, *popt)

fig = plt.figure()
ax = fig.gca(projection = &lt;span style="color: #228b22;"&gt;'3d'&lt;/span&gt;)

ax.plot(x1, x2, f, &lt;span style="color: #228b22;"&gt;'ko'&lt;/span&gt;, label=&lt;span style="color: #228b22;"&gt;'data'&lt;/span&gt;)
ax.plot(x1, x2, model(X, *popt), &lt;span style="color: #228b22;"&gt;'r-'&lt;/span&gt;, label=&lt;span style="color: #228b22;"&gt;'fit'&lt;/span&gt;)
ax.set_xlabel(&lt;span style="color: #228b22;"&gt;'x1'&lt;/span&gt;)
ax.set_ylabel(&lt;span style="color: #228b22;"&gt;'x2'&lt;/span&gt;)
ax.set_zlabel(&lt;span style="color: #228b22;"&gt;'f(x1,x2)'&lt;/span&gt;)

plt.savefig(&lt;span style="color: #228b22;"&gt;'images/graphical-mulvar-4.png'&lt;/span&gt;)
&lt;/pre&gt;
&lt;/div&gt;

&lt;pre class="example"&gt;
[ 3.21694798  1.9728254 ]
[  3.25873623   6.59792994  10.29473657  13.68011436  17.29161001
  23.62366445]
&lt;/pre&gt;

&lt;p&gt;&lt;img src="/img/./images/graphical-mulvar-1.png"&gt;&lt;p&gt;

&lt;p&gt;&lt;img src="/img/./images/graphical-mulvar-2.png"&gt;&lt;p&gt;

&lt;p&gt;&lt;img src="/img/./images/graphical-mulvar-3.png"&gt;&lt;p&gt;

&lt;p&gt;&lt;img src="/img/./images/graphical-mulvar-4.png"&gt;&lt;p&gt;

&lt;p&gt;
It can be difficult to figure out initial guesses for nonlinear fitting problems. For one and two dimensional systems, graphical techniques may be useful to visualize how the summed squared error between the model and data depends on the parameters.
&lt;/p&gt;
&lt;p&gt;Copyright (C) 2013 by John Kitchin. See the &lt;a href="/copying.html"&gt;License&lt;/a&gt; for information about copying.&lt;p&gt;&lt;p&gt;&lt;a href="/org/2013/02/18/Graphical-methods-to-help-get-initial-guesses-for-multivariate-nonlinear-regression.org"&gt;org-mode source&lt;/a&gt;&lt;p&gt;
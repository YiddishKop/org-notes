<p>One of the main reason I started to work on Deep Learning was to explain how human see and understand their environment.</p>

<p>This, to begin with, has mot much to do with Deep Learning. Whatn is the story?</p>

<p>Well, since the year 1997, I studied the neuroscience of how we see. How our eyes work, how our visual cortex forms a visual hierarchy, neurons, brains, etc. Too much literature to list here.
And <a href="http://culurciello.blogspot.com/2015/11/my-story-with-deep-learning-and-neural.html">this story is here</a></p>

<p>My original inspiration was <a href="http://serre-lab.clps.brown.edu/wp-content/uploads/2012/08/serre_etal-AIM-2004-026.pdf">the work of Thomas Serre</a> under the supervision of Tomaso Poggio at MIT.</p>

<p>Recently, <a href="http://arxiv.org/abs/1606.01167">this work</a> from Thomas Serre group show that we may not need very deep neural network to perform feed-forward classification. 
What maybe is needed, instead, is a shallower neural net, with recurrent processing, similar to <a href="http://arxiv.org/abs/1604.03640">what is proposed</a> by Poggio group at MIT.</p>

<p>In other words for getting better categorization, instead of more layers, we need more time multiple recurrent (feedback) passes.</p>

<p>This is in line with attentional mechanisms and visual search research, that shows that human use multipole fixation on the image to gather context and integrate information from multiple areas of the image.</p>

<p>Rapid categorization is useful to run away when in danger, but in most typical situations, we take our time to look.</p>
